{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d6a221",
   "metadata": {},
   "source": [
    "# Week 05 - Exploratory Data Analysis and Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac2f6a7",
   "metadata": {},
   "source": [
    "## Conditional Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71173cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# marbles dataframe\n",
    "import pandas as pd\n",
    "\n",
    "marbles = pd.read_csv('https://raw.githubusercontent.com/data-8/materials-sp22/main/materials/sp22/lab/lab10/marbles.csv')\n",
    "marbles.head(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b71bfb",
   "metadata": {},
   "source": [
    "### Marbles\n",
    "\n",
    "Imagine you and Samantha are playing a game in which you are given a marble and tasked to determine the marble's texture and size. You don't know anything about the marble you're given, but you know that Samantha drew it **uniformly at random** from a bag that contained the following marbles:\n",
    "\n",
    "* 1 large dull marble\n",
    "* 4 large shiny marbles\n",
    "* 2 small dull marbles\n",
    "* 6 small shiny marbles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f25f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby surface and size\n",
    "marbles.groupby(['size', 'surface'])['size'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef9d575",
   "metadata": {},
   "source": [
    "Knowing only what we've told you so far, what's the probability that the marble you're given was a large shiny marble?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5874a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 large shiney marbles / 13 marbles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006822b7",
   "metadata": {},
   "source": [
    "Suppose you overhear Samantha say that you were given a large marble. Does this somehow change the chance that your marble is shiny?  Let's find out.\n",
    "\n",
    "Let's assume that the marble you were given was equally likely to be any of the marbles, simply because we didn't know any better. That's why we looked at all the marbles to compute the probability that your marble was shiny.\n",
    "\n",
    "But assuming that you've been given a large marble, we can eliminate some of these possibilities. In particular, you can't have been given a small shiny marble or a small dull marble.\n",
    "\n",
    "You're still equally likely to have been given any of the remaining marbles, because you don't know any other information. \n",
    "\n",
    "What's the probability Samantha gives you a shiny marble, knowing that she gave you a large marble?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842f7033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby surface and size\n",
    "marbles.groupby(['size', 'surface'])['size'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given that you already have a large marble\n",
    "# we have 5 large marbles 4 of which are shiny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f982a",
   "metadata": {},
   "source": [
    "### Conditional Probability Formula\n",
    "\n",
    "$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$\n",
    "\n",
    "Dependent Intersection: $P(A \\cap B) = P(A) * P(B|A)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27f9bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = shiny\n",
    "# B = large\n",
    "# ((10/13) * (4/10)) / (5/13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac8133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using tables as a short cut to solve problems\n",
    "marbles.groupby(['size', 'surface'])['size'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c116a62",
   "metadata": {},
   "source": [
    "### Power (Sensitivity) vs. Confidence (Specificity)\n",
    "\n",
    "* Sensitivity: correctly identifying someone with a disease\n",
    "* Specificity: correctly identifying someone without a disease\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/books/NBK557491/\n",
    "\n",
    "<img src='https://www.statisticshowto.com/wp-content/uploads/2015/04/statistical-power.png' />\n",
    "\n",
    "<pre>\n",
    "                    predicted\n",
    "                   |  0   |  1     \n",
    "           -----------------------  ----------------------------------------------\n",
    "           0       |  {tn}  |  {fp}    tnr (specificity)   |  fpr (type I error) \n",
    "  actual   -----------------------  ----------------------------------------------\n",
    "           1       |  {fn}   |  {tp}   fnr (type II error) |  tpr (sensitivity, recall)\n",
    "\n",
    "                     npv  | fdr\n",
    "           ----------------------------\n",
    "                     for  | precision (ppv)\n",
    "\n",
    "</pre>\n",
    "\n",
    "If I were to describe it using the language of classification, statistical power concerns the probability we find a true positive (the effect truly is not the null effect, and we have correctly detected it). Indeed, the type 2 error rate is the false negative rate and power is 1-false negative rate, hence true positive rate.\n",
    "\n",
    "Demetri Pananos (https://stats.stackexchange.com/users/111259/demetri-pananos), Why Power = P(True Positive) in Hypothesis testing?, URL (version: 2021-07-07): https://stats.stackexchange.com/q/533589\n",
    "\n",
    "https://en.wikipedia.org/wiki/False_positives_and_false_negatives\n",
    "\n",
    "* Type I Error: $\\alpha$\n",
    "* Type II Error: $\\beta$\n",
    "* Beta is directly related to the power of a test. Power relates to how likely a test is to distinguish an actual effect from one you could expect to happen by chance alone. Beta plus the power of a test is always equal to 1. Usually, researchers will refer to the power of a test (e.g. a power of .8), leaving the beta level (.2 in this case) as implied. https://www.statisticshowto.com/beta-level/\n",
    "* The statistical power of a binary hypothesis test is the probability that the test correctly rejects the null hypothesis $H_{0}$ when a specific alternative hypothesis $H_{a}$ is true. It is commonly denoted by $1-\\beta$ , and represents the chances of a \"true positive\" detection conditional on the actual existence of an effect to detect. Statistical power ranges from 0 to 1, and as the power of a test increases, the probability $\\beta$  of making a type II error by wrongly failing to reject the null hypothesis decreases. https://en.wikipedia.org/wiki/Power_of_a_testHypothesis testing\n",
    "As I already mentioned, the definition most learners of statistics come to first for beta and alpha are about hypothesis testing.\n",
    "\n",
    "### Hypothesis testing\n",
    "\n",
    "https://www.theanalysisfactor.com/confusing-statistical-terms-1-alpha-and-beta/\n",
    "\n",
    "α (Alpha) is the probability of Type I error in any hypothesis test–incorrectly rejecting the null hypothesis.\n",
    "\n",
    "β (Beta) is the probability of Type II error in any hypothesis test–incorrectly failing to reject the null hypothesis.  (1 – β is power)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d61eec9",
   "metadata": {},
   "source": [
    "## Coding Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492a63f4",
   "metadata": {},
   "source": [
    "### Numpy (Arrays)\n",
    "\n",
    "* Scalars\n",
    "* Vectors\n",
    "* Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98da83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to array\n",
    "import numpy as np\n",
    "\n",
    "my_list = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "print(type(my_list))\n",
    "my_array = np.array(my_list)\n",
    "print(type(my_array)) # n-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e204be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view list\n",
    "my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c4f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view array\n",
    "my_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e3e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 x 3 array\n",
    "my_kart = [['Baby Daisy', 'Baby Luigi', 'Baby Mario'], ['Birdo', 'Bowser', 'Donkey Kong'], ['Princess Peach', 'Isabelle', 'Koopa Troopa']]\n",
    "my_kart_array = np.array(my_kart)\n",
    "my_kart_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bce0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.zeroes\n",
    "np.zeros((3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d25916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrays from arange and reshape\n",
    "import numpy as np\n",
    "\n",
    "my_ndarray = np.arange(1, 5).reshape(2, 2)\n",
    "my_ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ac4918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalar multiplaction\n",
    "my_ndarray * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e4f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalar division\n",
    "my_ndarray / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3713b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# element wise multiplication\n",
    "my_ndarray * my_ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c64db98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot product\n",
    "print([list(a) for a in my_ndarray], end='')\n",
    "print()\n",
    "print([list(a) for a in my_ndarray], end='')\n",
    "np.dot(my_ndarray, my_ndarray)\n",
    "# 1 * 1 + 2 * 3, 1 * 2 + 2 * 4, 3 * 1 + 4 * 3, 3 * 2 + 4 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cc8c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://nbviewer.org/github/jmportilla/Udemy-notes/blob/master/Lec%209%20-Indexing%20Arrays.ipynb\n",
    "import numpy as np\n",
    "\n",
    "my_ndarray = np.arange(1, 17).reshape(4, 4)\n",
    "my_ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a064c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ndarray[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e17fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ndarray[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d1a1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ndarray[0:1, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fbd35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_ndarray)\n",
    "my_ndarray[:1,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26a3d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_ndarray)\n",
    "my_ndarray[:1,2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f0b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_ndarray)\n",
    "my_ndarray[:2,2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4101773",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_ndarray)\n",
    "my_ndarray[2:4,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd06c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "np.random.randint(10, size=9).reshape(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4155769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# universal functions\n",
    "import webbrowser\n",
    "\n",
    "url = 'https://numpy.org/doc/stable/reference/ufuncs.html'\n",
    "webbrowser.open(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3276abdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some descriptive statistics\n",
    "import numpy as np\n",
    "\n",
    "stats_array = np.random.randint(10, size=9).reshape(3, 3)\n",
    "print(stats_array)\n",
    "print('sum:\\t', stats_array.sum())\n",
    "print('mean:\\t', stats_array.mean().round(2))\n",
    "print('var:\\t', stats_array.var().round(2))\n",
    "print('std:\\t', stats_array.std().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2751f7b4",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c130ab52",
   "metadata": {},
   "source": [
    "### Univariate Analysis\n",
    "\n",
    "Univariate analysis is the simplest form of analyzing data. Uni means one, so in other words the data has only one variable... Univariate data does not answer questions about relationships between variables, but rather it is used to describe characteristics or attributes of a feature... (para 4).\n",
    "\n",
    "https://en.wikipedia.org/wiki/Univariate_(statistics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f25db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate data histogram: dataset from https://archive.ics.uci.edu/ml/datasets/Auto+MPG\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "cars = pd.read_csv('https://raw.githubusercontent.com/gitmystuff/INFO5502/main/Week_3-Data/auto-mpg.data', sep = '\\s+', header = None)\n",
    "cars.columns=['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin',  'car name']\n",
    "print(cars.head())\n",
    "sns.histplot(cars['acceleration'].dropna(), kde=True, bins=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f6c684",
   "metadata": {},
   "source": [
    "**Note on sns.histplot(data, kde=True, bins=10) in previous cell**\n",
    "\n",
    "* Kernel density estimation or KDE is a non-parametric way to estimate the probability density function of a random variable\n",
    "* The aim of KDE is to find probability density function (PDF) for a given dataset\n",
    "\n",
    "https://www.homeworkhelponline.net/blog/math/tutorial-kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1453a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate data with pie chart\n",
    "cars['cylinders'].value_counts().plot.pie();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521020af",
   "metadata": {},
   "source": [
    "### Bivariate Analysis\n",
    "\n",
    "Can be used to describe the relationship between two variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fce60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bivariate scatter plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(cars['weight'], cars['mpg'])\n",
    "plt.xlabel('weight')\n",
    "plt.ylabel('mpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db94a2d7",
   "metadata": {},
   "source": [
    "### Multivariate Analysis\n",
    "\n",
    "Multivariate data involves two or more variables and provides another visual dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb1d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate example\n",
    "import seaborn as sns\n",
    "\n",
    "sns.scatterplot(data=cars, x='weight', y='mpg', size='acceleration');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3fbdda",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "* Getting to know your data: center, spread, shape\n",
    "* Data types: numerical, categorical, nominal, ordinal, boolean\n",
    "* Cardinality, duplications, and missing data\n",
    "* Outliers\n",
    "* Engineer features with too many labels\n",
    "* Understanding relationships between variables: feature with feature, feature with target\n",
    "* Feature engineering\n",
    "* Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8f8720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "import pandas as pd\n",
    "\n",
    "grades = pd.read_csv('class-grades4.csv', index_col=0)\n",
    "grades.drop(['index'], axis=1, inplace=True)\n",
    "print(grades.shape)\n",
    "print(grades.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd00ebc",
   "metadata": {},
   "source": [
    "### Constant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78565d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values and then check how many unique values are in each variable\n",
    "few_values = [\n",
    "    val for val in grades.columns if len(grades[val].fillna(0).unique()) == 1\n",
    "]\n",
    "\n",
    "few_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d19da9",
   "metadata": {},
   "source": [
    "### Quasi Constant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f563eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quasi constant values (sometimes these may be boolean features)\n",
    "for val in grades.columns.sort_values():\n",
    "    if (len(grades[val].unique()) < 3):\n",
    "        print(grades[val].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb9230c",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939728f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate rows\n",
    "grades[grades.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3a7829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate rows\n",
    "grades.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f04119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check of duplicate columns\n",
    "duplicate_variables = []\n",
    "for i in range(0, len(grades.columns)):\n",
    "    orig = grades.columns[i]\n",
    "\n",
    "    for dupe in grades.columns[i + 1:]:\n",
    "        if grades[orig].equals(grades[dupe]):\n",
    "            duplicate_variables.append(dupe)\n",
    "            print(f'{orig} looks the same as {dupe}')\n",
    "            \n",
    "duplicate_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b7b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the variables that are duplicated or low in variance\n",
    "grades.drop(['Quiz', 'Student', 'Misc', 'Nothing'], axis=1, inplace=True)\n",
    "grades.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2943330c",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dd510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for nulls\n",
    "grades.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729d5d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the shape of variables that are numerical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grades.hist()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b76cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values with mean and median\n",
    "grades['Midterm'].fillna(round(grades['Midterm'].mean(), 2), inplace=True)\n",
    "grades['Final'].fillna(round(grades['Final'].mean(), 2), inplace=True)\n",
    "grades['FinalGrade'].fillna(round(grades['FinalGrade'].mean(), 2), inplace=True)\n",
    "grades['Assignment1'].fillna(grades['Assignment1'].median(), inplace=True)\n",
    "grades['Tutorial'].fillna(grades['Tutorial'].median(), inplace=True)\n",
    "grades.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30d9b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values with mode\n",
    "print(grades['TakeHome'].value_counts(dropna=False))\n",
    "print(grades['work_status'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ab3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace work_status with mode (not employed)\n",
    "grades['work_status'].fillna(grades['work_status'].mode()[0], inplace=True)\n",
    "grades.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0ec922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace TakeHome with function\n",
    "def convert_grade(row):\n",
    "    if len(str(row['TakeHome'])) > 1:\n",
    "        if row['Final'] >= 90:\n",
    "            return 'A'\n",
    "        if row['Final'] >= 80:\n",
    "            return 'B'\n",
    "        if row['Final'] >= 70:\n",
    "            return 'C'\n",
    "        if row['Final'] >= 60:\n",
    "            return 'D'\n",
    "        if row['Final'] < 60:\n",
    "            return 'F'\n",
    "    else:\n",
    "        return row['TakeHome']\n",
    "        \n",
    "grades['TakeHome'] = grades.apply(convert_grade, axis=1)\n",
    "grades['TakeHome'].fillna('Missing', inplace=True)\n",
    "print(grades['TakeHome'].value_counts())\n",
    "print(grades.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeeab62",
   "metadata": {},
   "source": [
    "### Engineer Features With Too Many Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f9fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many different home destination labels are there?\n",
    "grades['home.dest'].value_counts(dropna=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07985a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# null home.dest values?\n",
    "print(len(grades[grades['home.dest'].isnull()]))\n",
    "grades[grades['home.dest'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c3de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cat_home(r):\n",
    "    text = str(r['home.dest']).strip()\n",
    "    if bool(re.search('[A-Z]{2}$', text[-2:])):\n",
    "        return 'North America'\n",
    "    elif text == 'nan':\n",
    "        return 'Missing'\n",
    "    else:\n",
    "        return 'Not North America'\n",
    "\n",
    "grades['cat_home'] = grades.apply(cat_home, axis=1)\n",
    "\n",
    "print(grades['cat_home'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b30c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(grades.drop(['FinalGrade', 'home.dest', 'name'], axis=1), grades['FinalGrade'], test_size=.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bd7342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statistics example\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88df338",
   "metadata": {},
   "source": [
    "### Quartiles\n",
    "\n",
    "https://en.wikipedia.org/wiki/Interquartile_range\n",
    "\n",
    "Interquartile range<br />\n",
    "Whiskers<br />\n",
    "Fence: https://www.statisticshowto.com/upper-and-lower-fences/\n",
    "\n",
    "Outliers<br />\n",
    "Boxplots<br />\n",
    "Violin plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7157f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment histogram\n",
    "X_train['Assignment1'].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e0a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment boxplot\n",
    "X_train.boxplot(column=['Assignment1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdee4afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment violinplot\n",
    "import seaborn as sns\n",
    "\n",
    "sns.violinplot(x=X_train['Assignment1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb81d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in X_train._get_numeric_data().columns[1:]:\n",
    "    q1 = grades[feat].quantile(0.25)\n",
    "    q3 = grades[feat].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_fence = (q1 - 1.5 * iqr).round()\n",
    "    upper_fence = (q3 + 1.5 * iqr).round()\n",
    "    lower_count = grades[feat][grades[feat] < lower_fence].count()\n",
    "    upper_count = grades[feat][grades[feat] > upper_fence].count()\n",
    "    print(f'{feat} outliers = {lower_count + upper_count}: lower_fence: {lower_fence}, upper_fence: {upper_fence}, lower_count: {lower_count}, upper_count: {upper_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9d09f0",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "\n",
    "In statistics, correlation or dependence is any statistical relationship, whether causal or not, between two random variables or bivariate data. In the broadest sense correlation is any statistical association, though it actually refers to the degree to which a pair of variables are linearly related. Familiar examples of dependent phenomena include the correlation between the height of parents and their offspring, and the correlation between the price of a good and the quantity the consumers are willing to purchase... Correlations are useful because they can indicate a predictive relationship that can be exploited in practice (paras. 1 - 2).\n",
    "\n",
    "https://en.wikipedia.org/wiki/Correlation.\n",
    "\n",
    "### Correlation Between Features\n",
    "\n",
    "* anything above .9 do something about it\n",
    "* between .5 and .7 may need a closer look\n",
    "\n",
    "Correlation does not imply cause causation. Warm days on the beach, ice cream, and shark bites.\n",
    "\n",
    "### Pearson’s r (correlation coefficient)\n",
    "\n",
    "$\\rho_{x,y} = \\frac{cov(x,y)}{\\sigma_x\\sigma_y} = \\frac{\\frac{1}{N}\\sum(x-\\bar{x})(y-\\bar{y})}{\\sqrt\\frac{\\sum(x-\\bar{x})^2}{N}\\sqrt\\frac{\\sum(y-\\bar{y})^2}{N}}  = \\frac{\\sum(x-\\bar{x})(y-\\bar{y})}{\\sqrt{\\sum(x-\\bar{x})^2}\\sqrt{\\sum(y-\\bar{y})^2}}$\n",
    "\n",
    "* Shows linear relationship between two continuous variables\n",
    "* How one variable changes as another variable changes\n",
    "* Measures both strength and direction\n",
    "\n",
    "https://statistics.laerd.com/statistical-guides/pearson-correlation-coefficient-statistical-guide.php<br />\n",
    "https://www.mygreatlearning.com/blog/covariance-vs-correlation/\n",
    "\n",
    "### Covariance\n",
    "\n",
    "$cov(x, y) = \\frac{1}{N} \\sum_{i=1}^{N}(x_i - \\bar{x}) (y_i - \\bar{y})$\n",
    "\n",
    "* Shows how variables change together\n",
    "* A measure of correlation\n",
    "* Measures direction\n",
    "\n",
    "### Multicollinearity\n",
    "\n",
    "* Makes it difficult to determine which independent variables are influencing the dependent variable\n",
    "\n",
    "### Correlation vs Multicollinearity\n",
    "\n",
    "* Correlation measures how two or more variables move together (good between independent and dependent variables)\n",
    "* (Mutli)collinearity shows a linear relationship, usually high, between features\n",
    "\n",
    "### Variance Inflation Factor (VIF)\n",
    "\n",
    "https://towardsdatascience.com/statistics-in-python-collinearity-and-multicollinearity-4cc4dcd82b3f \n",
    "\n",
    "* Minimum possible value is one\n",
    "* Values over 10 mean multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3252bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation heat map\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "ptext = f\"Pearson r: {round(stats.pearsonr(X_train['Midterm'], X_train['Final'])[0], 2)}\"\n",
    "sns.regplot(x='Midterm', y='Final', data=X_train, ci=None,\n",
    "            line_kws={'color': 'red', 'label': ptext});\n",
    "                      \n",
    "plt.legend()\n",
    "plt.show();\n",
    "\n",
    "# correlation matrix\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# compute the correlation matrix\n",
    "corr = X_train.corr()\n",
    "\n",
    "# generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# set up the matplotlib figure\n",
    "f, ax = plt.subplots()\n",
    "\n",
    "# generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e14418",
   "metadata": {},
   "source": [
    "There's not much correlation between the independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cdb8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns pairplot\n",
    "import seaborn as sns\n",
    "\n",
    "eda_data = X_train.copy()\n",
    "eda_data['FinalGrade'] = y_train\n",
    "\n",
    "sns.pairplot(data=eda_data, corner=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2fbcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plots showing correlation\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(data=eda_data, x_vars=['Assignment1', 'Tutorial', 'Midterm', 'Final'], y_vars='FinalGrade', \n",
    "             kind='reg',\n",
    "             height=5,\n",
    "             aspect=0.8, \n",
    "             plot_kws={'line_kws':{'color':'red'}, 'scatter_kws': {'alpha': 0.5}});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9675a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation with target\n",
    "X_train.corrwith(y_train).plot.bar(\n",
    "        title = 'Correlation with Final Grade (Target)', rot = 45, grid = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15d65b6",
   "metadata": {},
   "source": [
    "The Final shows more than 80% correlation with the Final Grade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f2efc4",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "* https://matplotlib.org/stable/gallery/index.html \n",
    "* http://seaborn.pydata.org/examples/\n",
    "* https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html \n",
    "* https://towardsdatascience.com/a-complete-guide-to-plotting-categorical-variables-with-seaborn-bfe54db66bec\n",
    "\n",
    "### Some Types of Plots\n",
    "\n",
    "https://towardsdatascience.com/intro-to-dynamic-visualization-with-python-animations-and-interactive-plots-f72a7fb69245\n",
    "\n",
    "* Static\n",
    "* Dynamic\n",
    "* Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c857ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train review\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2567a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f32ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram\n",
    "X_train['Final'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d40b384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie plot\n",
    "grades['Prefix'].value_counts().plot(kind='pie');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67aba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot\n",
    "grades[['Assignment1', 'Final']].mean().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ce5b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bivariate\n",
    "grades.plot.scatter(x='Midterm', y='Final', c='black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d100d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate\n",
    "grades.plot.scatter(x='Midterm', y='Final', c='age', colormap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c2137c",
   "metadata": {},
   "source": [
    "## Groupby \n",
    "\n",
    "https://towardsdatascience.com/meet-the-hardest-functions-of-pandas-part-ii-f8029a2b0c9b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d71cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby\n",
    "X_train.groupby('sex')['Final'].agg(['min', 'max', 'mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea22c1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bar chart; https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html\n",
    "X_train.groupby('sex')['Final'].agg(['min', 'max', 'mean']).plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9256066b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# horizontal bar chart\n",
    "X_train.groupby('sex')['Final'].agg(['min', 'max', 'mean']).plot(kind='barh');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd4a0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked bar\n",
    "X_train.groupby('sex')['Final'].agg(['min', 'max', 'mean']).plot.bar(stacked=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a2a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 4 grades grouped by sex\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "female_scores = grades.query('`sex` == \"female\"')\n",
    "male_scores = grades.query('`sex` == \"male\"')\n",
    "ax = female_scores[['Assignment1', 'Tutorial', 'Midterm', 'Final']].mean().plot(kind='line', label='female')\n",
    "male_scores[['Assignment1', 'Tutorial', 'Midterm', 'Final']].mean().plot(ax=ax, label='male')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001740c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby plot one liner\n",
    "X_train.groupby('sex')[['Assignment1', 'Tutorial', 'Midterm', 'Final']].agg('mean').transpose().plot(kind='line');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a9564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby breakdown\n",
    "grouped = X_train.groupby('sex')[['Assignment1', 'Tutorial', 'Midterm', 'Final']].agg('mean')\n",
    "print(grouped)\n",
    "print('---' * 20)\n",
    "print(grouped.transpose())\n",
    "print('---' * 20)\n",
    "grouped.transpose().plot(kind='line');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe334ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby two liner\n",
    "grouped = X_train.groupby('sex')[['Assignment1', 'Tutorial', 'Midterm', 'Final']].agg('mean')\n",
    "grouped.transpose().plot(kind='line');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b30478b",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b750986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recheck our data\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b44e317",
   "metadata": {},
   "source": [
    "### Bi-Label Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2439b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi-label mapping\n",
    "X_train['sex'] = X_train['sex'].map({'female':1,'male':0})\n",
    "X_test['sex'] = X_test['sex'].map({'female':1,'male':0})\n",
    "\n",
    "X_train['scholarship'] = X_train['scholarship'].map({'yes':1,'no':0})\n",
    "X_test['scholarship'] = X_test['scholarship'].map({'yes':1,'no':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93217fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b29f56",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dece53ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn OneHotEncoder\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "# https://stackoverflow.com/questions/50473381/scikit-learns-labelbinarizer-vs-onehotencoder\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "pets = ['dog', 'cat', 'cat', 'dog', 'turtle', 'cat', 'cat', 'turtle', 'dog', 'cat']\n",
    "le = LabelEncoder()\n",
    "int_values = le.fit_transform(pets)\n",
    "print('Data:', pets)\n",
    "print('Label Encoder:', int_values)\n",
    "int_values = int_values.reshape(len(int_values), 1)\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe = ohe.fit_transform(int_values)\n",
    "print('One Hot Encoder:\\n', ohe)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "print('Label Binarizer:\\n', lb.fit_transform(int_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbe88a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pandas get_dummies\n",
    "import pandas as pd\n",
    "\n",
    "X_dummy = pd.get_dummies(X_train, drop_first=True)\n",
    "y_dummy = pd.get_dummies(X_test, drop_first=True)\n",
    "print(X_dummy.shape)\n",
    "print(y_dummy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f059f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sklearn one hot encoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(categories='auto', drop='first', sparse=False, handle_unknown='ignore')\n",
    "\n",
    "cat_features = ['Prefix', 'TakeHome', 'work_status', 'cat_home']\n",
    "ohe_train = ohe.fit_transform(X_train[cat_features])\n",
    "ohe_train = pd.DataFrame(ohe_train, columns=ohe.get_feature_names_out(cat_features))\n",
    "ohe_train.index = X_train.index\n",
    "X_train = X_train.join(ohe_train)\n",
    "X_train.drop(cat_features, axis=1, inplace=True)\n",
    "\n",
    "ohe_test = ohe.transform(X_test[cat_features])\n",
    "ohe_test = pd.DataFrame(ohe_test, columns=ohe.get_feature_names_out(cat_features))\n",
    "ohe_test.index = X_test.index\n",
    "X_test = X_test.join(ohe_test)\n",
    "X_test.drop(cat_features, axis=1, inplace=True)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a158d6",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "* https://github.com/codingnest/FeatureSelection/blob/master/Data%20Science%20Lifecycle%20-%20Feature%20Selection%20(Filter%2C%20Wrapper%2C%20Embedded%20and%20Hybrid%20Methods).ipynb\n",
    "* https://www.analyticsvidhya.com/blog/2020/10/a-comprehensive-guide-to-feature-selection-using-wrapper-methods-in-python/\n",
    "\n",
    "<img src='https://editor.analyticsvidhya.com/uploads/84353IMAGE1.png' alt='feature selection' />\n",
    "\n",
    "### Feature-engine\n",
    "\n",
    "https://feature-engine.readthedocs.io/en/latest/\n",
    "\n",
    "### Filter Methods\n",
    "\n",
    "* Constant, Quasi Constant, and Duplicated Features\n",
    "* Correlation\n",
    "* Variance\n",
    "* Mutual Information\n",
    "* Chi-Square Test\n",
    "* ANOVA\n",
    "* SelectKBest\n",
    "\n",
    "### Wrapper Methods\n",
    "\n",
    "* Backward, Forward, Stepwise Selection (Regression)\n",
    "\n",
    "### Embedded Methods\n",
    "\n",
    "* Coefficients (Regression)\n",
    "* Lasso Regularization\n",
    "* Tree Importance\n",
    "\n",
    "### Hybrid Methods\n",
    "\n",
    "* Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbd38ca",
   "metadata": {},
   "source": [
    "### Mutual Information\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html\n",
    "\n",
    "Estimate mutual information for a continuous target variable.\n",
    "\n",
    "Mutual information (MI) between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f695561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mutual information between X_train and y_train\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "mi = mutual_info_regression(X_train, y_train)\n",
    "mi = pd.Series(mi)\n",
    "mi.index = X_train.columns\n",
    "mi.sort_values(ascending=False).plot.bar()\n",
    "plt.ylabel('Mutual Information')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
